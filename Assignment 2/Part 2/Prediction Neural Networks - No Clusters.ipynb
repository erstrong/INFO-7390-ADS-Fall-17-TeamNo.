{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks for Entire Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emily-air13/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/emily-air13/anaconda3/lib/python3.6/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n",
      "/Users/emily-air13/anaconda3/lib/python3.6/site-packages/sklearn/learning_curve.py:22: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the functions are moved. This module will be removed in 0.20\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.externals import joblib\n",
    "from sklearn import *\n",
    "from sklearn import cluster\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
    "from math import sqrt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#k_means = joblib.load(open('kmeans.pkl', 'rb'))\n",
    "loans = pd.read_csv('../loanstats.csv')\n",
    "#loans['kcluster'] = k_means.labels_\n",
    "\n",
    "\n",
    "loans['term'] = loans['term'].map(lambda a: int(a.strip(' months')))\n",
    "loans['application_type'] = loans['application_type'].map(lambda a: 1 if a=='Joint App' else 0)\n",
    "\n",
    "def elength(a):\n",
    "    if (a=='n/a'):\n",
    "        return 0\n",
    "    elif (a=='10+ years'):\n",
    "        return 10\n",
    "    elif (a=='1 year'):\n",
    "        return 1\n",
    "    elif (a=='< 1 year'):\n",
    "        return 0.5\n",
    "    else:\n",
    "        return float(a.strip(' years'))\n",
    "    \n",
    "loans['emp_length'] = loans['emp_length'].map(lambda a: elength(a))\n",
    "\n",
    "loans['revol_util'] = loans['revol_util'].map(lambda a: float(a.strip('%')))\n",
    "\n",
    "homes = pd.get_dummies(loans['home_ownership'], prefix='home')\n",
    "loans = loans.join(homes)\n",
    "loans.drop('home_ownership', axis=1, inplace=True)\n",
    "\n",
    "states = pd.get_dummies(loans['addr_state'], prefix='st')\n",
    "loans = loans.join(states)\n",
    "loans.drop('addr_state', axis=1, inplace=True)\n",
    "\n",
    "loans.drop('grade', axis=1, inplace=True)\n",
    "loans.drop('sub_grade', axis=1, inplace=True)\n",
    "loans.drop('set', axis=1, inplace=True)\n",
    "loans.drop('emp_title', axis=1, inplace=True)\n",
    "loans.drop('timestamp', axis=1, inplace=True)\n",
    "loans.drop('issue_d', axis=1, inplace=True)\n",
    "loans.drop('last_credit_pull_d', axis=1, inplace=True)\n",
    "loans.drop('title', axis=1, inplace=True)\n",
    "loans.drop('purpose', axis=1, inplace=True)\n",
    "loans.drop('next_pymnt_d', axis=1, inplace=True)\n",
    "loans.drop('zip_code', axis=1, inplace=True)\n",
    "loans.drop('last_fico_range_high', axis=1, inplace=True)\n",
    "loans.drop('fico_range_high', axis=1, inplace=True)\n",
    "loans.drop('last_fico_range_low', axis=1, inplace=True)\n",
    "loans.drop('installment', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 10.99,  10.99,  11.99, ...,  30.89,  30.65,  30.94])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array=loans.values\n",
    "\n",
    "Y=array[:,3]\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x1=array[:,1:3]\n",
    "x2=array[:,4:]\n",
    "X=np.hstack((x1,x2))\n",
    "\n",
    "#X[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "# Fit only to the training data\n",
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now apply the transformations to the data:\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mlp = MLPRegressor(hidden_layer_sizes=(50,20,10),\n",
    "                   activation='relu',solver='adam',verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(50, 20, 10), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|metric |train            |test             | \n",
      "|rms    |3.2487803987338206|3.2881395995300355|\n",
      "|mae    |2.47136613424    |2.49108494803    |\n",
      "|mape   |20.0276457632    |20.1883338662    |\n"
     ]
    }
   ],
   "source": [
    "ptrain = mlp.predict(X_train)\n",
    "ptest = mlp.predict(X_test)\n",
    "rms_train = sqrt(mean_squared_error(Y_train, ptrain))\n",
    "rms_test = sqrt(mean_squared_error(Y_test, ptest))\n",
    "mae_train = mean_absolute_error(Y_train, ptrain)\n",
    "mae_test = mean_absolute_error(Y_test, ptest)\n",
    "mape_train = np.mean(np.abs((Y_train - ptrain) / Y_train)) * 100\n",
    "mape_test = np.mean(np.abs((Y_test - ptest) / Y_test)) * 100\n",
    "\n",
    "print('|metric |train            |test             | \\n|rms    |'+str(rms_train)+'|'+str(rms_test)+'|\\n|mae    |'\n",
    "      +str(mae_train)+'    |'+str(mae_test)+'    |\\n|mape   |'+str(mape_train)+'    |'+str(mape_test)+'    |')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempt 2 - more layers, more iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|metric |train            |test             | \n",
      "|rms    |3.211610772535971|3.3017922207376618|\n",
      "|mae    |2.4493166298    |2.50775723833    |\n",
      "|mape   |19.8904881652    |20.3304348662    |\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPRegressor(hidden_layer_sizes=(100,40,20), max_iter=400)\n",
    "mlp.fit(X_train,Y_train)\n",
    "ptrain = mlp.predict(X_train)\n",
    "ptest = mlp.predict(X_test)\n",
    "rms_train = sqrt(mean_squared_error(Y_train, ptrain))\n",
    "rms_test = sqrt(mean_squared_error(Y_test, ptest))\n",
    "mae_train = mean_absolute_error(Y_train, ptrain)\n",
    "mae_test = mean_absolute_error(Y_test, ptest)\n",
    "mape_train = np.mean(np.abs((Y_train - ptrain) / Y_train)) * 100\n",
    "mape_test = np.mean(np.abs((Y_test - ptest) / Y_test)) * 100\n",
    "\n",
    "print('|metric |train            |test             | \\n|rms    |'+str(rms_train)+'|'+str(rms_test)+'|\\n|mae    |'\n",
    "      +str(mae_train)+'    |'+str(mae_test)+'    |\\n|mape   |'+str(mape_train)+'    |'+str(mape_test)+'    |')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Attempt 3 - Fewer Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emily-air13/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|metric |train            |test             | \n",
      "|rms    |3.2371243107776513|3.2943924378114713|\n",
      "|mae    |2.46208961386    |2.49812983386    |\n",
      "|mape   |19.9516715847    |20.2085794857    |\n"
     ]
    }
   ],
   "source": [
    "#from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "mlp = MLPRegressor(hidden_layer_sizes=(500,200,100), max_iter=10)\n",
    "mlp.fit(X_train,Y_train)\n",
    "ptrain = mlp.predict(X_train)\n",
    "ptest = mlp.predict(X_test)\n",
    "rms_train = sqrt(mean_squared_error(Y_train, ptrain))\n",
    "rms_test = sqrt(mean_squared_error(Y_test, ptest))\n",
    "mae_train = mean_absolute_error(Y_train, ptrain)\n",
    "mae_test = mean_absolute_error(Y_test, ptest)\n",
    "mape_train = np.mean(np.abs((Y_train - ptrain) / Y_train)) * 100\n",
    "mape_test = np.mean(np.abs((Y_test - ptest) / Y_test)) * 100\n",
    "\n",
    "print('|metric |train            |test             | \\n|rms    |'+str(rms_train)+'|'+str(rms_test)+'|\\n|mae    |'\n",
    "      +str(mae_train)+'    |'+str(mae_test)+'    |\\n|mape   |'+str(mape_train)+'    |'+str(mape_test)+'    |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
