{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emily-air13/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/emily-air13/anaconda3/lib/python3.6/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n",
      "/Users/emily-air13/anaconda3/lib/python3.6/site-packages/sklearn/learning_curve.py:22: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the functions are moved. This module will be removed in 0.20\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.externals import joblib\n",
    "from sklearn import *\n",
    "from sklearn import cluster\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
    "from math import sqrt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loans = pd.read_csv('../loanstats.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def manual_clusters(fico):\n",
    "    if fico > 720:\n",
    "        return 'Group1'\n",
    "    elif fico > 700:\n",
    "        return 'Group2'\n",
    "    elif fico > 690: \n",
    "        return 'Group3'\n",
    "    elif fico > 680: # amnt < 25000 \n",
    "        return 'Group4'\n",
    "    elif fico > 670:\n",
    "        return 'Group5'\n",
    "    else:\n",
    "        return 'Group6'\n",
    "\n",
    "loans['manual_cat'] = loans.apply(lambda x: manual_clusters(x['fico_range_low']), axis=1)\n",
    "\n",
    "loans.drop('grade', axis=1, inplace=True)\n",
    "loans.drop('sub_grade', axis=1, inplace=True)\n",
    "loans.drop('set', axis=1, inplace=True)\n",
    "loans.drop('timestamp', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emily-air13/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/Users/emily-air13/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/Users/emily-air13/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/Users/emily-air13/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/Users/emily-air13/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "/Users/emily-air13/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "man1 = loans[loans['manual_cat']=='Group1']\n",
    "man2 = loans[loans['manual_cat']=='Group2']\n",
    "man3 = loans[loans['manual_cat']=='Group3']\n",
    "man4 = loans[loans['manual_cat']=='Group4']\n",
    "man5 = loans[loans['manual_cat']=='Group5']\n",
    "man6 = loans[loans['manual_cat']=='Group6']\n",
    "\n",
    "man1.drop('manual_cat',axis=1,inplace=True)\n",
    "man2.drop('manual_cat',axis=1,inplace=True)\n",
    "man3.drop('manual_cat',axis=1,inplace=True)\n",
    "man4.drop('manual_cat',axis=1,inplace=True)\n",
    "man5.drop('manual_cat',axis=1,inplace=True)\n",
    "man6.drop('manual_cat',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|metric |train            |test             | \n",
      "|rms    |2.6478634393802514|2.786699088168375|\n",
      "|mae    |1.92905559942    |2.01897337632    |\n",
      "|mape   |19.9620164953    |20.8038703533    |\n"
     ]
    }
   ],
   "source": [
    "array=man1.values\n",
    "Y=array[:,3]\n",
    "x1=array[:,1:3]\n",
    "x2=array[:,4:]\n",
    "X=np.hstack((x1,x2))\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "mlp = MLPRegressor(hidden_layer_sizes=(50,20,10))\n",
    "mlp.fit(X_train,Y_train)\n",
    "ptrain = mlp.predict(X_train)\n",
    "ptest = mlp.predict(X_test)\n",
    "rms_train = sqrt(mean_squared_error(Y_train, ptrain))\n",
    "rms_test = sqrt(mean_squared_error(Y_test, ptest))\n",
    "mae_train = mean_absolute_error(Y_train, ptrain)\n",
    "mae_test = mean_absolute_error(Y_test, ptest)\n",
    "mape_train = np.mean(np.abs((Y_train - ptrain) / Y_train)) * 100\n",
    "mape_test = np.mean(np.abs((Y_test - ptest) / Y_test)) * 100\n",
    "#results.append([name, rms_train, rms_test, mae_train, mae_test, mape_train, mape_test])\n",
    "\n",
    "print('|metric |train            |test             | \\n|rms    |'+str(rms_train)+'|'+str(rms_test)+'|\\n|mae    |'\n",
    "      +str(mae_train)+'    |'+str(mae_test)+'    |\\n|mape   |'+str(mape_train)+'    |'+str(mape_test)+'    |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|metric |train            |test             | \n",
      "|rms    |3.1038996256993197|3.2566573051404624|\n",
      "|mae    |2.3828233969    |2.49023120569    |\n",
      "|mape   |21.6693559133    |22.5204093244    |\n"
     ]
    }
   ],
   "source": [
    "array=man2.values\n",
    "Y=array[:,3]\n",
    "x1=array[:,1:3]\n",
    "x2=array[:,4:]\n",
    "X=np.hstack((x1,x2))\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "mlp = MLPRegressor(hidden_layer_sizes=(50,20,10))\n",
    "mlp.fit(X_train,Y_train)\n",
    "ptrain = mlp.predict(X_train)\n",
    "ptest = mlp.predict(X_test)\n",
    "rms_train = sqrt(mean_squared_error(Y_train, ptrain))\n",
    "rms_test = sqrt(mean_squared_error(Y_test, ptest))\n",
    "mae_train = mean_absolute_error(Y_train, ptrain)\n",
    "mae_test = mean_absolute_error(Y_test, ptest)\n",
    "mape_train = np.mean(np.abs((Y_train - ptrain) / Y_train)) * 100\n",
    "mape_test = np.mean(np.abs((Y_test - ptest) / Y_test)) * 100\n",
    "#results.append([name, rms_train, rms_test, mae_train, mae_test, mape_train, mape_test])\n",
    "\n",
    "print('|metric |train            |test             | \\n|rms    |'+str(rms_train)+'|'+str(rms_test)+'|\\n|mae    |'\n",
    "      +str(mae_train)+'    |'+str(mae_test)+'    |\\n|mape   |'+str(mape_train)+'    |'+str(mape_test)+'    |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|metric |train            |test             | \n",
      "|rms    |3.2826285098500585|3.476651281417829|\n",
      "|mae    |2.47174468682    |2.60420318076    |\n",
      "|mape   |19.7778266576    |20.7612607947    |\n"
     ]
    }
   ],
   "source": [
    "array=man3.values\n",
    "Y=array[:,3]\n",
    "x1=array[:,1:3]\n",
    "x2=array[:,4:]\n",
    "X=np.hstack((x1,x2))\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "mlp = MLPRegressor(hidden_layer_sizes=(50,20,10))\n",
    "mlp.fit(X_train,Y_train)\n",
    "ptrain = mlp.predict(X_train)\n",
    "ptest = mlp.predict(X_test)\n",
    "rms_train = sqrt(mean_squared_error(Y_train, ptrain))\n",
    "rms_test = sqrt(mean_squared_error(Y_test, ptest))\n",
    "mae_train = mean_absolute_error(Y_train, ptrain)\n",
    "mae_test = mean_absolute_error(Y_test, ptest)\n",
    "mape_train = np.mean(np.abs((Y_train - ptrain) / Y_train)) * 100\n",
    "mape_test = np.mean(np.abs((Y_test - ptest) / Y_test)) * 100\n",
    "#results.append([name, rms_train, rms_test, mae_train, mae_test, mape_train, mape_test])\n",
    "\n",
    "print('|metric |train            |test             | \\n|rms    |'+str(rms_train)+'|'+str(rms_test)+'|\\n|mae    |'\n",
    "      +str(mae_train)+'    |'+str(mae_test)+'    |\\n|mape   |'+str(mape_train)+'    |'+str(mape_test)+'    |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|metric |train            |test             | \n",
      "|rms    |3.379003777778928|3.534176996871215|\n",
      "|mae    |2.57406267555    |2.68487305935    |\n",
      "|mape   |20.0442424247    |20.9583711778    |\n"
     ]
    }
   ],
   "source": [
    "array=man4.values\n",
    "Y=array[:,3]\n",
    "x1=array[:,1:3]\n",
    "x2=array[:,4:]\n",
    "X=np.hstack((x1,x2))\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "mlp = MLPRegressor(hidden_layer_sizes=(50,20,10))\n",
    "mlp.fit(X_train,Y_train)\n",
    "ptrain = mlp.predict(X_train)\n",
    "ptest = mlp.predict(X_test)\n",
    "rms_train = sqrt(mean_squared_error(Y_train, ptrain))\n",
    "rms_test = sqrt(mean_squared_error(Y_test, ptest))\n",
    "mae_train = mean_absolute_error(Y_train, ptrain)\n",
    "mae_test = mean_absolute_error(Y_test, ptest)\n",
    "mape_train = np.mean(np.abs((Y_train - ptrain) / Y_train)) * 100\n",
    "mape_test = np.mean(np.abs((Y_test - ptest) / Y_test)) * 100\n",
    "#results.append([name, rms_train, rms_test, mae_train, mae_test, mape_train, mape_test])\n",
    "\n",
    "print('|metric |train            |test             | \\n|rms    |'+str(rms_train)+'|'+str(rms_test)+'|\\n|mae    |'\n",
    "      +str(mae_train)+'    |'+str(mae_test)+'    |\\n|mape   |'+str(mape_train)+'    |'+str(mape_test)+'    |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|metric |train            |test             | \n",
      "|rms    |3.37209585664966|3.5107302787710704|\n",
      "|mae    |2.60265315867    |2.70151167699    |\n",
      "|mape   |19.4572654345    |20.2692410845    |\n"
     ]
    }
   ],
   "source": [
    "array=man5.values\n",
    "Y=array[:,3]\n",
    "x1=array[:,1:3]\n",
    "x2=array[:,4:]\n",
    "X=np.hstack((x1,x2))\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "mlp = MLPRegressor(hidden_layer_sizes=(50,20,10))\n",
    "mlp.fit(X_train,Y_train)\n",
    "ptrain = mlp.predict(X_train)\n",
    "ptest = mlp.predict(X_test)\n",
    "rms_train = sqrt(mean_squared_error(Y_train, ptrain))\n",
    "rms_test = sqrt(mean_squared_error(Y_test, ptest))\n",
    "mae_train = mean_absolute_error(Y_train, ptrain)\n",
    "mae_test = mean_absolute_error(Y_test, ptest)\n",
    "mape_train = np.mean(np.abs((Y_train - ptrain) / Y_train)) * 100\n",
    "mape_test = np.mean(np.abs((Y_test - ptest) / Y_test)) * 100\n",
    "#results.append([name, rms_train, rms_test, mae_train, mae_test, mape_train, mape_test])\n",
    "\n",
    "print('|metric |train            |test             | \\n|rms    |'+str(rms_train)+'|'+str(rms_test)+'|\\n|mae    |'\n",
    "      +str(mae_train)+'    |'+str(mae_test)+'    |\\n|mape   |'+str(mape_train)+'    |'+str(mape_test)+'    |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|metric |train            |test             | \n",
      "|rms    |3.412622419039398|3.473454833307991|\n",
      "|mae    |2.62053867086    |2.66755172318    |\n",
      "|mape   |18.1064141079    |18.4067820063    |\n"
     ]
    }
   ],
   "source": [
    "array=man6.values\n",
    "Y=array[:,3]\n",
    "x1=array[:,1:3]\n",
    "x2=array[:,4:]\n",
    "X=np.hstack((x1,x2))\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "mlp = MLPRegressor(hidden_layer_sizes=(50,20,10))\n",
    "mlp.fit(X_train,Y_train)\n",
    "ptrain = mlp.predict(X_train)\n",
    "ptest = mlp.predict(X_test)\n",
    "rms_train = sqrt(mean_squared_error(Y_train, ptrain))\n",
    "rms_test = sqrt(mean_squared_error(Y_test, ptest))\n",
    "mae_train = mean_absolute_error(Y_train, ptrain)\n",
    "mae_test = mean_absolute_error(Y_test, ptest)\n",
    "mape_train = np.mean(np.abs((Y_train - ptrain) / Y_train)) * 100\n",
    "mape_test = np.mean(np.abs((Y_test - ptest) / Y_test)) * 100\n",
    "#results.append([name, rms_train, rms_test, mae_train, mae_test, mape_train, mape_test])\n",
    "\n",
    "print('|metric |train            |test             | \\n|rms    |'+str(rms_train)+'|'+str(rms_test)+'|\\n|mae    |'\n",
    "      +str(mae_train)+'    |'+str(mae_test)+'    |\\n|mape   |'+str(mape_train)+'    |'+str(mape_test)+'    |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
