{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emily-air13/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/emily-air13/anaconda3/lib/python3.6/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n",
      "/Users/emily-air13/anaconda3/lib/python3.6/site-packages/sklearn/learning_curve.py:22: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the functions are moved. This module will be removed in 0.20\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.externals import joblib\n",
    "from sklearn import *\n",
    "from sklearn import cluster\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
    "from math import sqrt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k_means = joblib.load(open('kmeans.pkl', 'rb'))\n",
    "loans = pd.read_csv('../loanstats.csv')\n",
    "loans['kcluster'] = k_means.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loans['term'] = loans['term'].map(lambda a: int(a.strip(' months')))\n",
    "loans['application_type'] = loans['application_type'].map(lambda a: 1 if a=='Joint App' else 0)\n",
    "\n",
    "def elength(a):\n",
    "    if (a=='n/a'):\n",
    "        return 0\n",
    "    elif (a=='10+ years'):\n",
    "        return 10\n",
    "    elif (a=='1 year'):\n",
    "        return 1\n",
    "    elif (a=='< 1 year'):\n",
    "        return 0.5\n",
    "    else:\n",
    "        return float(a.strip(' years'))\n",
    "    \n",
    "loans['emp_length'] = loans['emp_length'].map(lambda a: elength(a))\n",
    "\n",
    "loans['revol_util'] = loans['revol_util'].map(lambda a: float(a.strip('%')))\n",
    "\n",
    "homes = pd.get_dummies(loans['home_ownership'], prefix='home')\n",
    "loans = loans.join(homes)\n",
    "loans.drop('home_ownership', axis=1, inplace=True)\n",
    "\n",
    "states = pd.get_dummies(loans['addr_state'], prefix='st')\n",
    "loans = loans.join(states)\n",
    "loans.drop('addr_state', axis=1, inplace=True)\n",
    "\n",
    "loans.drop('grade', axis=1, inplace=True)\n",
    "loans.drop('sub_grade', axis=1, inplace=True)\n",
    "loans.drop('set', axis=1, inplace=True)\n",
    "loans.drop('emp_title', axis=1, inplace=True)\n",
    "loans.drop('timestamp', axis=1, inplace=True)\n",
    "loans.drop('issue_d', axis=1, inplace=True)\n",
    "loans.drop('last_credit_pull_d', axis=1, inplace=True)\n",
    "loans.drop('title', axis=1, inplace=True)\n",
    "loans.drop('purpose', axis=1, inplace=True)\n",
    "loans.drop('next_pymnt_d', axis=1, inplace=True)\n",
    "loans.drop('zip_code', axis=1, inplace=True)\n",
    "loans.drop('last_fico_range_high', axis=1, inplace=True)\n",
    "loans.drop('fico_range_high', axis=1, inplace=True)\n",
    "loans.drop('last_fico_range_low', axis=1, inplace=True)\n",
    "loans.drop('installment', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emily-air13/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/Users/emily-air13/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/Users/emily-air13/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/Users/emily-air13/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "/Users/emily-air13/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n",
      "/Users/emily-air13/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/Users/emily-air13/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "kc0 = loans[loans['kcluster']==0]\n",
    "kc1 = loans[loans['kcluster']==1]\n",
    "kc2 = loans[loans['kcluster']==2]\n",
    "kc3 = loans[loans['kcluster']==3]\n",
    "kc4 = loans[loans['kcluster']==4]\n",
    "kc5 = loans[loans['kcluster']==5]\n",
    "kc6 = loans[loans['kcluster']==6]\n",
    "\n",
    "kc0.drop('kcluster', axis=1, inplace=True)\n",
    "kc1.drop('kcluster', axis=1, inplace=True)\n",
    "kc2.drop('kcluster', axis=1, inplace=True)\n",
    "kc3.drop('kcluster', axis=1, inplace=True)\n",
    "kc4.drop('kcluster', axis=1, inplace=True)\n",
    "kc5.drop('kcluster', axis=1, inplace=True)\n",
    "kc6.drop('kcluster', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|metric |train            |test             | \n",
      "|rms    |3.066613709137871|3.196394696240065|\n",
      "|mae    |2.34191621068    |2.44230116369    |\n",
      "|mape   |19.9523024255    |20.787755507    |\n"
     ]
    }
   ],
   "source": [
    "array=kc0.values\n",
    "Y=array[:,3]\n",
    "x1=array[:,1:3]\n",
    "x2=array[:,4:]\n",
    "X=np.hstack((x1,x2))\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "mlp = MLPRegressor(hidden_layer_sizes=(50,20,10))\n",
    "mlp.fit(X_train,Y_train)\n",
    "ptrain = mlp.predict(X_train)\n",
    "ptest = mlp.predict(X_test)\n",
    "rms_train = sqrt(mean_squared_error(Y_train, ptrain))\n",
    "rms_test = sqrt(mean_squared_error(Y_test, ptest))\n",
    "mae_train = mean_absolute_error(Y_train, ptrain)\n",
    "mae_test = mean_absolute_error(Y_test, ptest)\n",
    "mape_train = np.mean(np.abs((Y_train - ptrain) / Y_train)) * 100\n",
    "mape_test = np.mean(np.abs((Y_test - ptest) / Y_test)) * 100\n",
    "#results.append([name, rms_train, rms_test, mae_train, mae_test, mape_train, mape_test])\n",
    "\n",
    "print('|metric |train            |test             | \\n|rms    |'+str(rms_train)+'|'+str(rms_test)+'|\\n|mae    |'\n",
    "      +str(mae_train)+'    |'+str(mae_test)+'    |\\n|mape   |'+str(mape_train)+'    |'+str(mape_test)+'    |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|metric |train            |test             | \n",
      "|rms    |2.7117863398528215|2.8758832440427344|\n",
      "|mae    |2.07753765852    |2.20105015679    |\n",
      "|mape   |16.3273114554    |17.2521632035    |\n"
     ]
    }
   ],
   "source": [
    "array=kc1.values\n",
    "Y=array[:,3]\n",
    "x1=array[:,1:3]\n",
    "x2=array[:,4:]\n",
    "X=np.hstack((x1,x2))\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "mlp = MLPRegressor(hidden_layer_sizes=(50,20,10))\n",
    "mlp.fit(X_train,Y_train)\n",
    "ptrain = mlp.predict(X_train)\n",
    "ptest = mlp.predict(X_test)\n",
    "rms_train = sqrt(mean_squared_error(Y_train, ptrain))\n",
    "rms_test = sqrt(mean_squared_error(Y_test, ptest))\n",
    "mae_train = mean_absolute_error(Y_train, ptrain)\n",
    "mae_test = mean_absolute_error(Y_test, ptest)\n",
    "mape_train = np.mean(np.abs((Y_train - ptrain) / Y_train)) * 100\n",
    "mape_test = np.mean(np.abs((Y_test - ptest) / Y_test)) * 100\n",
    "#results.append([name, rms_train, rms_test, mae_train, mae_test, mape_train, mape_test])\n",
    "\n",
    "print('|metric |train            |test             | \\n|rms    |'+str(rms_train)+'|'+str(rms_test)+'|\\n|mae    |'\n",
    "      +str(mae_train)+'    |'+str(mae_test)+'    |\\n|mape   |'+str(mape_train)+'    |'+str(mape_test)+'    |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|metric |train            |test             | \n",
      "|rms    |3.636629613762908|3.8368202773499416|\n",
      "|mae    |2.64958144748    |2.7740505255    |\n",
      "|mape   |20.2305102252    |21.1082463535    |\n"
     ]
    }
   ],
   "source": [
    "array=kc2.values\n",
    "Y=array[:,3]\n",
    "x1=array[:,1:3]\n",
    "x2=array[:,4:]\n",
    "X=np.hstack((x1,x2))\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "mlp = MLPRegressor(hidden_layer_sizes=(50,20,10))\n",
    "mlp.fit(X_train,Y_train)\n",
    "ptrain = mlp.predict(X_train)\n",
    "ptest = mlp.predict(X_test)\n",
    "rms_train = sqrt(mean_squared_error(Y_train, ptrain))\n",
    "rms_test = sqrt(mean_squared_error(Y_test, ptest))\n",
    "mae_train = mean_absolute_error(Y_train, ptrain)\n",
    "mae_test = mean_absolute_error(Y_test, ptest)\n",
    "mape_train = np.mean(np.abs((Y_train - ptrain) / Y_train)) * 100\n",
    "mape_test = np.mean(np.abs((Y_test - ptest) / Y_test)) * 100\n",
    "#results.append([name, rms_train, rms_test, mae_train, mae_test, mape_train, mape_test])\n",
    "\n",
    "print('|metric |train            |test             | \\n|rms    |'+str(rms_train)+'|'+str(rms_test)+'|\\n|mae    |'\n",
    "      +str(mae_train)+'    |'+str(mae_test)+'    |\\n|mape   |'+str(mape_train)+'    |'+str(mape_test)+'    |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|metric |train            |test             | \n",
      "|rms    |3.4423975892742638|3.547005841632404|\n",
      "|mae    |2.61052378704    |2.68329004731    |\n",
      "|mape   |20.3196472082    |20.8530544519    |\n"
     ]
    }
   ],
   "source": [
    "array=kc3.values\n",
    "Y=array[:,3]\n",
    "x1=array[:,1:3]\n",
    "x2=array[:,4:]\n",
    "X=np.hstack((x1,x2))\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "mlp = MLPRegressor(hidden_layer_sizes=(50,20,10))\n",
    "mlp.fit(X_train,Y_train)\n",
    "ptrain = mlp.predict(X_train)\n",
    "ptest = mlp.predict(X_test)\n",
    "rms_train = sqrt(mean_squared_error(Y_train, ptrain))\n",
    "rms_test = sqrt(mean_squared_error(Y_test, ptest))\n",
    "mae_train = mean_absolute_error(Y_train, ptrain)\n",
    "mae_test = mean_absolute_error(Y_test, ptest)\n",
    "mape_train = np.mean(np.abs((Y_train - ptrain) / Y_train)) * 100\n",
    "mape_test = np.mean(np.abs((Y_test - ptest) / Y_test)) * 100\n",
    "#results.append([name, rms_train, rms_test, mae_train, mae_test, mape_train, mape_test])\n",
    "\n",
    "print('|metric |train            |test             | \\n|rms    |'+str(rms_train)+'|'+str(rms_test)+'|\\n|mae    |'\n",
    "      +str(mae_train)+'    |'+str(mae_test)+'    |\\n|mape   |'+str(mape_train)+'    |'+str(mape_test)+'    |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|metric |train            |test             | \n",
      "|rms    |2.720421029031796|2.853455515994795|\n",
      "|mae    |2.11265932355    |2.21630723149    |\n",
      "|mape   |17.6399405192    |18.5272599744    |\n"
     ]
    }
   ],
   "source": [
    "array=kc4.values\n",
    "Y=array[:,3]\n",
    "x1=array[:,1:3]\n",
    "x2=array[:,4:]\n",
    "X=np.hstack((x1,x2))\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "mlp = MLPRegressor(hidden_layer_sizes=(50,20,10))\n",
    "mlp.fit(X_train,Y_train)\n",
    "ptrain = mlp.predict(X_train)\n",
    "ptest = mlp.predict(X_test)\n",
    "rms_train = sqrt(mean_squared_error(Y_train, ptrain))\n",
    "rms_test = sqrt(mean_squared_error(Y_test, ptest))\n",
    "mae_train = mean_absolute_error(Y_train, ptrain)\n",
    "mae_test = mean_absolute_error(Y_test, ptest)\n",
    "mape_train = np.mean(np.abs((Y_train - ptrain) / Y_train)) * 100\n",
    "mape_test = np.mean(np.abs((Y_test - ptest) / Y_test)) * 100\n",
    "#results.append([name, rms_train, rms_test, mae_train, mae_test, mape_train, mape_test])\n",
    "\n",
    "print('|metric |train            |test             | \\n|rms    |'+str(rms_train)+'|'+str(rms_test)+'|\\n|mae    |'\n",
    "      +str(mae_train)+'    |'+str(mae_test)+'    |\\n|mape   |'+str(mape_train)+'    |'+str(mape_test)+'    |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|metric |train            |test             | \n",
      "|rms    |2.4735322490107117|2.547156870842096|\n",
      "|mae    |1.90541320089    |1.96188707667    |\n",
      "|mape   |14.0573497203    |14.4822755711    |\n"
     ]
    }
   ],
   "source": [
    "array=kc5.values\n",
    "Y=array[:,3]\n",
    "x1=array[:,1:3]\n",
    "x2=array[:,4:]\n",
    "X=np.hstack((x1,x2))\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "mlp = MLPRegressor(hidden_layer_sizes=(50,20,10))\n",
    "mlp.fit(X_train,Y_train)\n",
    "ptrain = mlp.predict(X_train)\n",
    "ptest = mlp.predict(X_test)\n",
    "rms_train = sqrt(mean_squared_error(Y_train, ptrain))\n",
    "rms_test = sqrt(mean_squared_error(Y_test, ptest))\n",
    "mae_train = mean_absolute_error(Y_train, ptrain)\n",
    "mae_test = mean_absolute_error(Y_test, ptest)\n",
    "mape_train = np.mean(np.abs((Y_train - ptrain) / Y_train)) * 100\n",
    "mape_test = np.mean(np.abs((Y_test - ptest) / Y_test)) * 100\n",
    "#results.append([name, rms_train, rms_test, mae_train, mae_test, mape_train, mape_test])\n",
    "\n",
    "print('|metric |train            |test             | \\n|rms    |'+str(rms_train)+'|'+str(rms_test)+'|\\n|mae    |'\n",
    "      +str(mae_train)+'    |'+str(mae_test)+'    |\\n|mape   |'+str(mape_train)+'    |'+str(mape_test)+'    |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|metric |train            |test             | \n",
      "|rms    |2.6080194642200327|2.7286924694218615|\n",
      "|mae    |2.01808081968    |2.11403875831    |\n",
      "|mape   |17.2246311117    |18.0484509125    |\n"
     ]
    }
   ],
   "source": [
    "array=kc6.values\n",
    "Y=array[:,3]\n",
    "x1=array[:,1:3]\n",
    "x2=array[:,4:]\n",
    "X=np.hstack((x1,x2))\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "mlp = MLPRegressor(hidden_layer_sizes=(50,20,10))\n",
    "mlp.fit(X_train,Y_train)\n",
    "ptrain = mlp.predict(X_train)\n",
    "ptest = mlp.predict(X_test)\n",
    "rms_train = sqrt(mean_squared_error(Y_train, ptrain))\n",
    "rms_test = sqrt(mean_squared_error(Y_test, ptest))\n",
    "mae_train = mean_absolute_error(Y_train, ptrain)\n",
    "mae_test = mean_absolute_error(Y_test, ptest)\n",
    "mape_train = np.mean(np.abs((Y_train - ptrain) / Y_train)) * 100\n",
    "mape_test = np.mean(np.abs((Y_test - ptest) / Y_test)) * 100\n",
    "#results.append([name, rms_train, rms_test, mae_train, mae_test, mape_train, mape_test])\n",
    "\n",
    "print('|metric |train            |test             | \\n|rms    |'+str(rms_train)+'|'+str(rms_test)+'|\\n|mae    |'\n",
    "      +str(mae_train)+'    |'+str(mae_test)+'    |\\n|mape   |'+str(mape_train)+'    |'+str(mape_test)+'    |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
