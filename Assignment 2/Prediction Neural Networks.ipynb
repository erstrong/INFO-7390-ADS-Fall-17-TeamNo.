{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.externals import joblib\n",
    "from sklearn import *\n",
    "from sklearn import cluster\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
    "from math import sqrt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k_means = joblib.load(open('kmeans.pkl', 'rb'))\n",
    "loans = pd.read_csv('loanstats.csv')\n",
    "loans['kcluster'] = k_means.labels_\n",
    "\n",
    "def manual_clusters(fico):\n",
    "    if fico > 720:\n",
    "        return 'Group1'\n",
    "    elif fico > 700:\n",
    "        return 'Group2'\n",
    "    elif fico > 690: \n",
    "        return 'Group3'\n",
    "    elif fico > 680: # amnt < 25000 \n",
    "        return 'Group4'\n",
    "    elif fico > 670:\n",
    "        return 'Group5'\n",
    "    else:\n",
    "        return 'Group6'\n",
    "\n",
    "loans['manual_cat'] = loans.apply(lambda x: manual_clusters(x['fico_range_low']), axis=1)\n",
    "\n",
    "loans['term'] = loans['term'].map(lambda a: int(a.strip(' months')))\n",
    "loans['application_type'] = loans['application_type'].map(lambda a: 1 if a=='Joint App' else 0)\n",
    "\n",
    "def elength(a):\n",
    "    if (a=='n/a'):\n",
    "        return 0\n",
    "    elif (a=='10+ years'):\n",
    "        return 10\n",
    "    elif (a=='1 year'):\n",
    "        return 1\n",
    "    elif (a=='< 1 year'):\n",
    "        return 0.5\n",
    "    else:\n",
    "        return float(a.strip(' years'))\n",
    "    \n",
    "loans['emp_length'] = loans['emp_length'].map(lambda a: elength(a))\n",
    "\n",
    "loans['revol_util'] = loans['revol_util'].map(lambda a: float(a.strip('%')))\n",
    "\n",
    "homes = pd.get_dummies(loans['home_ownership'], prefix='home')\n",
    "loans = loans.join(homes)\n",
    "loans.drop('home_ownership', axis=1, inplace=True)\n",
    "\n",
    "states = pd.get_dummies(loans['addr_state'], prefix='st')\n",
    "loans = loans.join(states)\n",
    "loans.drop('addr_state', axis=1, inplace=True)\n",
    "\n",
    "loans.drop('grade', axis=1, inplace=True)\n",
    "loans.drop('sub_grade', axis=1, inplace=True)\n",
    "loans.drop('set', axis=1, inplace=True)\n",
    "loans.drop('emp_title', axis=1, inplace=True)\n",
    "loans.drop('timestamp', axis=1, inplace=True)\n",
    "loans.drop('issue_d', axis=1, inplace=True)\n",
    "loans.drop('last_credit_pull_d', axis=1, inplace=True)\n",
    "loans.drop('title', axis=1, inplace=True)\n",
    "loans.drop('purpose', axis=1, inplace=True)\n",
    "loans.drop('next_pymnt_d', axis=1, inplace=True)\n",
    "loans.drop('zip_code', axis=1, inplace=True)\n",
    "loans.drop('last_fico_range_high', axis=1, inplace=True)\n",
    "loans.drop('fico_range_high', axis=1, inplace=True)\n",
    "loans.drop('last_fico_range_low', axis=1, inplace=True)\n",
    "loans.drop('installment', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entire Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loans_tot = loans.drop('manual_cat', axis=1)\n",
    "loans_tot.drop('kcluster', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 10.99,  10.99,  11.99, ...,  30.89,  30.65,  30.94])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array=loans_tot.values\n",
    "\n",
    "Y=array[:,3]\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  4.80000000e+03,   3.60000000e+01,   2.00000000e+00,\n",
       "         3.96000000e+04,   2.49000000e+00,   0.00000000e+00,\n",
       "         7.55000000e+02,   1.95000000e+02,   3.00000000e+00,\n",
       "         4.13600000e+03,   1.61000000e+01,   8.00000000e+00,\n",
       "         0.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n",
       "         4.13600000e+03,   1.61000000e+01,   0.00000000e+00,\n",
       "         1.04000000e+02,   2.50000000e+01,   0.00000000e+00,\n",
       "         2.50000000e+01,   3.00000000e+00,   0.00000000e+00,\n",
       "         2.00000000e+00,   2.00000000e+00,   4.00000000e+00,\n",
       "         1.00000000e+00,   7.00000000e+00,   2.00000000e+00,\n",
       "         3.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   2.57000000e+04,   0.00000000e+00,\n",
       "         1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1=array[:,1:3]\n",
    "x2=array[:,4:]\n",
    "X=np.hstack((x1,x2))\n",
    "\n",
    "X[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "# Fit only to the training data\n",
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now apply the transformations to the data:\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "mlp = MLPRegressor(hidden_layer_sizes=(50,20,10),\n",
    "                   activation='relu',solver='adam',verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(50, 20, 10), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|metric |train            |test             | \n",
      "|rms    |3.2487803987338206|3.2881395995300355|\n",
      "|mae    |2.47136613424    |2.49108494803    |\n",
      "|mape   |20.0276457632    |20.1883338662    |\n"
     ]
    }
   ],
   "source": [
    "ptrain = mlp.predict(X_train)\n",
    "ptest = mlp.predict(X_test)\n",
    "rms_train = sqrt(mean_squared_error(Y_train, ptrain))\n",
    "rms_test = sqrt(mean_squared_error(Y_test, ptest))\n",
    "mae_train = mean_absolute_error(Y_train, ptrain)\n",
    "mae_test = mean_absolute_error(Y_test, ptest)\n",
    "mape_train = np.mean(np.abs((Y_train - ptrain) / Y_train)) * 100\n",
    "mape_test = np.mean(np.abs((Y_test - ptest) / Y_test)) * 100\n",
    "\n",
    "print('|metric |train            |test             | \\n|rms    |'+str(rms_train)+'|'+str(rms_test)+'|\\n|mae    |'\n",
    "      +str(mae_train)+'    |'+str(mae_test)+'    |\\n|mape   |'+str(mape_train)+'    |'+str(mape_test)+'    |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mlp = MLPRegressor(hidden_layer_sizes=(100,40,20), max_iter=400)\n",
    "mlp.fit(X_train,Y_train)\n",
    "ptrain = mlp.predict(X_train)\n",
    "ptest = mlp.predict(X_test)\n",
    "rms_train = sqrt(mean_squared_error(Y_train, ptrain))\n",
    "rms_test = sqrt(mean_squared_error(Y_test, ptest))\n",
    "mae_train = mean_absolute_error(Y_train, ptrain)\n",
    "mae_test = mean_absolute_error(Y_test, ptest)\n",
    "mape_train = np.mean(np.abs((Y_train - ptrain) / Y_train)) * 100\n",
    "mape_test = np.mean(np.abs((Y_test - ptest) / Y_test)) * 100\n",
    "\n",
    "print('|metric |train            |test             | \\n|rms    |'+str(rms_train)+'|'+str(rms_test)+'|\\n|mae    |'\n",
    "      +str(mae_train)+'    |'+str(mae_test)+'    |\\n|mape   |'+str(mape_train)+'    |'+str(mape_test)+'    |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "\n",
    "# Define an output queue\n",
    "output = mp.Queue()\n",
    "\n",
    "\n",
    "# define a example function\n",
    "def rand_string(length, output):\n",
    "    \"\"\" Generates a random string of numbers, lower- and uppercase chars. \"\"\"\n",
    "    rand_str = ''.join(random.choice(\n",
    "                        string.ascii_lowercase\n",
    "                        + string.ascii_uppercase\n",
    "                        + string.digits)\n",
    "                   for i in range(length))\n",
    "    output.put(rand_str)\n",
    "\n",
    "# Setup a list of processes that we want to run\n",
    "processes = [mp.Process(target=rand_string, args=(5, output)) for x in range(4)]\n",
    "\n",
    "# Run processes\n",
    "for p in processes:\n",
    "    p.start()\n",
    "\n",
    "# Exit the completed processes\n",
    "for p in processes:\n",
    "    p.join()\n",
    "\n",
    "# Get process results from the output queue\n",
    "results = [output.get() for p in processes]\n",
    "\n",
    "print(results)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
