{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis of Zillow Data Set\n",
    "\n",
    "The data:\n",
    "\n",
    "* properties_2017.csv is a sample of all properties from 2017 listed on Zillow through Sept\n",
    "* train_2017.csv contains dates, propertyids, and logerror for each transaction in 2017 through Sept\n",
    "* The same files are available for 2016 (entire year)\n",
    "* Not all properties have transactions\n",
    "* logerror=log(Zestimate)âˆ’log(SalePrice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import geopy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df17 = pd.read_csv('properties_2017.csv', low_memory=False)\n",
    "df_transactions17 = pd.read_csv('train_2017.csv', low_memory=False)\n",
    "df_merged17 = pd.merge(df17, df_transactions17, on='parcelid', how='right')\n",
    "df_merged17.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df16 = pd.read_csv('properties_2016.csv', low_memory=False)\n",
    "df_transactions16 = pd.read_csv('train_2016_v2.csv', low_memory=False)\n",
    "df_merged16 = pd.merge(df16, df_transactions16, on='parcelid', how='right')\n",
    "df_merged16.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_merged16['latitude'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_merged16['longitude'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The latitudes and longitudes are listed in the data sets with size decimal places but no decimal points, so they need to be corrected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_merged17['latitude'] = df_merged17['latitude'] / 1000000\n",
    "df_merged17['longitude'] = df_merged17['longitude'] / 1000000\n",
    "df_merged16['latitude'] = df_merged16['latitude'] / 1000000\n",
    "df_merged16['longitude'] = df_merged16['longitude'] / 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_merged17['taxdelinquencyyear'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tax delinquency years are listed as YY, with the first digit missing if it is a 0. Since some of the years are from the 1990s, we need to fix this so that they will sort in the correct order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def convertyears(x):\n",
    "    if x > 9 and x < 20:\n",
    "        t = '20' + str(x)\n",
    "        return float(t)\n",
    "    elif x <= 9:\n",
    "        t = '200' + str(x)\n",
    "        return float(t)\n",
    "    elif x > 20:\n",
    "        t = '19' + str(x)\n",
    "        return float(t)\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "\n",
    "\n",
    "df_merged17['taxdelinquencyyear'] = df_merged17['taxdelinquencyyear'].map(lambda a: convertyears(a))\n",
    "df_merged16['taxdelinquencyyear'] = df_merged16['taxdelinquencyyear'].map(lambda a: convertyears(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_merged16['taxdelinquencyyear'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_merged16['transactiondate'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The transaction dates are in a string format, so we need to conver them to datetime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "format = '%Y-%m-%d'\n",
    "df_merged16['transactiondate'] = df_merged16['transactiondate'].map(lambda a: datetime.datetime.strptime(a, format))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_merged17['transactiondate'] = df_merged17['transactiondate'].map(lambda a: datetime.datetime.strptime(a, format))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_merged17['transactiondate'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For some analyses we will be looking at both data sets together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_merged16['setyear'] = 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_merged17['setyear'] = 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_total = df_merged16.append(df_merged17, ignore_index=True)\n",
    "df_total.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_total['setyear'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_total.groupby('setyear')['logerror'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "means = df_total.groupby('transactiondate')['logerror'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "plt.scatter(df_total['transactiondate'].tolist(), df_total['logerror'], s =10, c = 'blue')\n",
    "plt.scatter(means.index, means, s =10, c = 'red')\n",
    "plt.title('LogError Over Time')\n",
    "plt.xlabel('Transaction Date')\n",
    "plt.ylabel('Logerror')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing Data and Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "missing_percents = (len(df_total.index) - df_total.count())/len(df_total.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "missing_percents.sort_values(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "missing_percents.plot(kind='barh', figsize=(20,30))\n",
    "plt.yticks(size=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets also look at this by year to make sure the two sets don't have major differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "missing_percents16 = (len(df_merged16.index) - df_merged16.count())/len(df_merged16.index)\n",
    "missing_percents17 = (len(df_merged17.index) - df_merged17.count())/len(df_merged17.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "missing_percents16.sort_values(inplace=True)\n",
    "temp = pd.DataFrame(missing_percents17, columns=['2017'])\n",
    "missing_combined = pd.DataFrame(missing_percents16, columns=['2016'])\n",
    "missing_combined = missing_combined.join(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "missing_combined.plot.barh(figsize=(20,40))\n",
    "plt.yticks(size=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outlier Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "categorical=['airconditioningtypeid','architecturalstyletypeid','buildingclasstypeid','decktypeid','fips',\n",
    "             'hashottuborspa','heatingorsystemtypeid','propertycountylandusecode','propertylandusetypeid','propertyzoningdesc',\n",
    "             'rawcensustractandblock','regionidcity','regionidcounty','regionidneighborhood','regionidzip',\n",
    "             'storytypeid','typeconstructiontypeid','fireplaceflag','taxdelinquencyflag','censustractandblock',\n",
    "             'transactiondate']\n",
    "numerical = ['basementsqft','bathroomcnt','bedroomcnt','buildingqualitytypeid','calculatedbathnbr',\n",
    "             'finishedfloor1squarefeet','calculatedfinishedsquarefeet','finishedsquarefeet12',\n",
    "             'finishedsquarefeet13','finishedsquarefeet15','finishedsquarefeet50','finishedsquarefeet6',\n",
    "             'fireplacecnt','fullbathcnt','garagecarcnt','garagetotalsqft','latitude','longitude',\n",
    "             'lotsizesquarefeet','poolcnt','poolsizesum','pooltypeid10','pooltypeid2','pooltypeid7','roomcnt',\n",
    "             'threequarterbathnbr','unitcnt','yardbuildingsqft17','yardbuildingsqft26','yearbuilt','numberofstories',\n",
    "             'structuretaxvaluedollarcnt','taxvaluedollarcnt','assessmentyear','landtaxvaluedollarcnt','taxamount',\n",
    "             'taxdelinquencyyear','logerror']\n",
    "\n",
    "# Ignore: parcelid, setyear\n",
    "\n",
    "rooms = ['bathroomcnt','bedroomcnt','calculatedbathnbr','fullbathcnt','roomcnt','threequarterbathnbr']\n",
    "sqft = ['basementsqft','finishedfloor1squarefeet','calculatedfinishedsquarefeet','finishedsquarefeet12',\n",
    "        'finishedsquarefeet13','finishedsquarefeet15','finishedsquarefeet50','finishedsquarefeet6',\n",
    "        'garagetotalsqft']\n",
    "lotsqft=['lotsizesquarefeet']\n",
    "yard=['yardbuildingsqft17','yardbuildingsqft26']\n",
    "pools=['poolcnt','pooltypeid10','pooltypeid2','pooltypeid7']\n",
    "poolsz = 'poolsizesum'\n",
    "features = ['buildingqualitytypeid','fireplacecnt','garagecarcnt','numberofstories']\n",
    "units= ['unitcnt']\n",
    "taxes=['structuretaxvaluedollarcnt','taxvaluedollarcnt','landtaxvaluedollarcnt','taxamount']\n",
    "years = ['yearbuilt','assessmentyear','taxdelinquencyyear']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2017 Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_merged17.boxplot(rooms, figsize=(10,  10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_merged17.boxplot(sqft, figsize=(20,  10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_merged17.boxplot(lotsqft)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_merged17.boxplot(pools)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_merged17.boxplot(poolsz)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_merged17.boxplot(features)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_merged17.boxplot(yard)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_merged17.boxplot(misc)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_merged17.boxplot(taxes)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_merged17.boxplot(years)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "outliers1=df_merged17[df_merged17['calculatedbathnbr'] > 12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "outliers2 = df_merged17[df_merged17['unitcnt'] > 20]\n",
    "outliers2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "outliers3 = df_merged17[df_merged17['lotsizesquarefeet'] > 2000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "outliers17 = outliers1.append(outliers2)\n",
    "outliers17 = outliers17.append(outliers3)\n",
    "pd.set_option('display.max_columns', 65)\n",
    "outliers17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For the lot size outliers, almost all of them have one of two lot sizes (3589145 or 6971010). This suggests there is something irregular with the values and in our data wrangling we will replace them with the median. \n",
    "* The outliers based on bathroom count are consistent in having outliers in most features, and are thus likely mansions in the LA area and accurately refelect the skew of the data. \n",
    "* For the unit count outliers, the property land use type id include a triplex, a quadruplex, and a mixed use building. The values are thus most likely data entry errors and we are replacing the values with the median."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2016 Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_merged16.boxplot(rooms, figsize=(10,  10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_merged16.boxplot(sqft, figsize=(20,  10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_merged16.boxplot(lotsqft)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_merged16.boxplot(yard)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_merged16.boxplot(pools)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_merged16.boxplot(poolsz)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_merged16.boxplot(features)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_merged16.boxplot(misc)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_merged16.boxplot(taxes)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_merged16.boxplot(years)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "outliers4=df_merged16[df_merged16['calculatedbathnbr'] > 10]\n",
    "outliers4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "outliers5 = df_merged16[df_merged16['unitcnt'] > 20]\n",
    "outliers5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "outliers6 = df_merged16[df_merged16['lotsizesquarefeet'] > 2000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "outliers16 = outliers4.append(outliers5)\n",
    "outliers16 = outliers16.append(outliers6)\n",
    "pd.set_option('display.max_columns', 65)\n",
    "outliers16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For the lot size outliers, they again have the same two values (3589145 or 6971010). In our data wrangling we will replace them with the median. \n",
    "* For the outliers based on unit counts, the property landuse type ids are complexes of planned units (269) and condos (266). The data such as room counts appear to be about individual units, so it appears these are sales of individual units and the number of units is for the entire complex. We will replace these with the median.\n",
    "* For the outliers based on bathroom count, one has irregularities in other columns such as a calculated finished square footage of 66, so we will be removing that one from the data set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for other outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def lotsclean(x):\n",
    "    if x == 3589145 or x == 6971010:\n",
    "        return df_total['lotsizesquarefeet'].median()\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "\n",
    "df_total['lotsizesquarefeet'] = df_total['lotsizesquarefeet'].map(lambda a: lotsclean(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def unitsclean(x):\n",
    "    if x > 20:\n",
    "        return df_total['unitcnt'].median()\n",
    "    else: return x\n",
    "\n",
    "\n",
    "df_total['unitcnt'] = df_total['unitcnt'].map(lambda a: unitsclean(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_total=df_total[df_total['bathroomcnt']<20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_total['propertylandusetypeid'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_total.boxplot(rooms, figsize=(10,  10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Over and Under Estimating\n",
    "Since none of the numerical values have a clear correlation with log error, we want to look to see if the relationship is non-linear by examinging both over and under estimates\n",
    "\n",
    "(Idea from: https://www.kaggle.com/philippsp/exploratory-analysis-zillow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "numerical = ['bathroomcnt','bedroomcnt','buildingqualitytypeid','calculatedbathnbr',\n",
    "             'calculatedfinishedsquarefeet','finishedsquarefeet12',\n",
    "             'fireplacecnt','fullbathcnt','garagecarcnt','garagetotalsqft','latitude','longitude',\n",
    "             'lotsizesquarefeet','poolcnt','roomcnt','unitcnt','yearbuilt','numberofstories',\n",
    "              'structuretaxvaluedollarcnt','taxvaluedollarcnt','assessmentyear','landtaxvaluedollarcnt','taxamount',\n",
    "             'taxdelinquencyyear','logerror']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.regplot(x=df_total['bathroomcnt'],y=df_total['logerror'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num = df_total[numerical]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(round(len(num.columns) / 3), 3, figsize=(30, 60))\n",
    "\n",
    "for i, ax in enumerate(fig.axes):\n",
    "    if i < len(num):\n",
    "        sns.regplot(x=num.columns[i], y=num['logerror'], data=num, ax=ax)\n",
    "        #plt.title(numerical[i] + \" vs logerror\")\n",
    "        \n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(30,60))\n",
    "i = 1\n",
    "for column in numerical:\n",
    "    a = df_total.groupby(column)['logerror'].mean()\n",
    "    sub = fig.add_subplot(9, 3, i)\n",
    "    sub.scatter(a.index, a, c=\"g\")\n",
    "    sub.set_title(column + \" vs logerror\")\n",
    "    #sub.xlabel(column)\n",
    "    #sub.ylabel('logerror')\n",
    "    i+=1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "yr = df_total.groupby('yearbuilt')['logerror'].mean()\n",
    "#plt.scatter(yr.index, yr, c=\"g\")\n",
    "sns.regplot(x=df_total['yearbuilt'],y=df_total['logerror'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "barm = df_total.groupby('calculatedbathnbr')['logerror'].mean()\n",
    "plt.scatter(barm.index, barm, c=\"r\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "berm = df_total.groupby('bedroomcnt')['logerror'].mean()\n",
    "plt.scatter(berm.index, berm, c=\"r\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "quality = df_total.groupby('buildingqualitytypeid')['logerror'].mean()\n",
    "plt.scatter(quality.index, quality, c=\"r\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sqft = df_total.groupby('calculatedfinishedsquarefeet')['logerror'].mean()\n",
    "plt.scatter(sqft.index, sqft, c=\"b\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fire = df_total.groupby('fireplacecnt')['logerror'].mean()\n",
    "plt.scatter(fire.index, fire, c=\"b\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gar = df_total.groupby('garagecarcnt')['logerror'].mean()\n",
    "plt.scatter(gar.index, gar, c=\"r\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gars = df_total.groupby('garagetotalsqft')['logerror'].mean()\n",
    "plt.scatter(gars.index, gars, c=\"r\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lat = df_total.groupby('latitude')['logerror'].mean()\n",
    "plt.scatter(lat.index, lat, c=\"r\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lon = df_total.groupby('longitude')['logerror'].mean()\n",
    "plt.scatter(lon.index, lon, c=\"g\")\n",
    "plt.show()\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lot = df_total.groupby('lotsizesquarefeet')['logerror'].mean()\n",
    "plt.scatter(lot.index, lot, c=\"b\")\n",
    "plt.show()        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(df_total['poolcnt'], df_total['logerror'], c=\"g\")\n",
    "plt.show()        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rm = df_total.groupby('roomcnt')['logerror'].mean()\n",
    "plt.scatter(rm.index, rm, c=\"b\")\n",
    "plt.show()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "unit = df_total.groupby('unitcnt')['logerror'].mean()\n",
    "plt.scatter(unit.index, unit, c=\"b\")\n",
    "plt.show()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "stories = df_total.groupby('numberofstories')['logerror'].mean()\n",
    "plt.scatter(stories.index, stories, c=\"r\")\n",
    "plt.show()       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "strut = df_total.groupby('structuretaxvaluedollarcnt')['logerror'].mean()\n",
    "plt.scatter(strut.index, strut, c=\"r\")\n",
    "plt.show()       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "strut = df_total.groupby('taxvaluedollarcnt')['logerror'].mean()\n",
    "plt.scatter(strut.index, strut, c=\"r\")\n",
    "plt.show()       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "land = df_total.groupby('landtaxvaluedollarcnt')['logerror'].mean()\n",
    "plt.scatter(land.index, land, c=\"r\")\n",
    "plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tax = df_total.groupby('taxamount')['logerror'].mean()\n",
    "plt.scatter(tax.index, tax, c=\"r\")\n",
    "plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "td = df_total.groupby('taxdelinquencyyear')['logerror'].mean()\n",
    "plt.scatter(td.index, td, c=\"r\")\n",
    "plt.show()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Location Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# #### Missing Location Information Analysis\n",
    "# \n",
    "# Fields: \n",
    "# * regionidzip\n",
    "# * regionidcity\n",
    "# * regionidcounty\n",
    "# * regionidneighborhood\n",
    "# * fips\n",
    "# * latitude\n",
    "# * longitude\n",
    "\n",
    "df_merged['regionidzip'].describe()\n",
    "\n",
    "\n",
    "# There appears to be an invalid US zip code for the max. Examine all impossible US zip codes\n",
    "temp = df_merged[df_merged['regionidzip'] > 100000]\n",
    "\n",
    "temp['regionidzip']\n",
    "\n",
    "\n",
    "# All of the entries have the same invalid zip. Look at the county the zip code is associated with.\n",
    "temp['regionidcounty']\n",
    "\n",
    "\n",
    "# All have the same county. Get all entries in that county\n",
    "\n",
    "temp2 = df_merged[df_merged['regionidcounty'] == 3101]\n",
    "temp2.groupby('regionidzip').count()\n",
    "\n",
    "temp2['regionidzip'].mode()\n",
    "\n",
    "\n",
    "# This is not a US zip code. In spot checking, some of these zip codes are from CA, some are from OR, and some don't exist. Look at the other region identifiers:\n",
    "\n",
    "df_merged.groupby('regionidcounty').count()\n",
    "\n",
    "df_merged.groupby('regionidcity').count()\n",
    "\n",
    "df_merged.groupby('regionidneighborhood').count()\n",
    "df_merged.groupby('fips').count()\n",
    "\n",
    "\n",
    "# FIPS Codes:\n",
    "# * 6037: LA County - count is same as county code 3101\n",
    "# * 6059: Orange County - count is same as county code 1286\n",
    "# * 6111: Ventura County - count is same as county code 2061\n",
    "# \n",
    "# Verify mapping: \n",
    "\n",
    "pd.crosstab(df_merged['fips'],df_merged['regionidcounty'])\n",
    "\n",
    "\n",
    "# FIPS and RegionIDCounty contain identical information. For feature selection we will use FIPS since it has real-world meaning.\n",
    "\n",
    "pd.crosstab(df_merged['regionidneighborhood'],df_merged['fips'])\n",
    "\n",
    "pd.crosstab(df_merged['regionidcity'],df_merged['fips'])\n",
    "\n",
    "pd.crosstab(df_merged['regionidzip'],df_merged['fips'])\n",
    "\n",
    "\n",
    "nbcorr = df_merged[df_merged['fips']==6111]\n",
    "\n",
    "\n",
    "pd.crosstab(nbcorr['regionidneighborhood'],nbcorr['regionidzip'])\n",
    "\n",
    "\n",
    "# Even though the zip codes are fake, they do correspong to specific collections of neighborhoods, and it thus seems likely that Zillow did a 1:1 substitution when randomizing them. Since neighborhoods are more granular, they will be more useful for analysis.\n",
    "\n",
    "# #### Latitude and Longitude\n",
    "\n",
    "df_merged['latitude'].describe()\n",
    "\n",
    "df_merged['longitude'].describe()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df_total.iloc[0]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = str(a['latitude']) + \",\" + str(a['longitude'])\n",
    "string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geolocator = Nominatim()\n",
    "location = geolocator.reverse(string)\n",
    "location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location.raw['address']['postcode']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#t = ['latitude','longitude']\n",
    "#test = df_total[t].head()\n",
    "\n",
    "import time\n",
    "\n",
    "def zipcalc(a, b):\n",
    "    geolocator = Nominatim()\n",
    "    string = str(a) + \",\" + str(b)\n",
    "    location = geolocator.reverse(string)\n",
    "    try:\n",
    "        return location.raw['address']['postcode']\n",
    "    except KeyError:\n",
    "        return np.nan\n",
    "    except GeocoderTimedOut:\n",
    "        time.sleep(2)\n",
    "        zipcalc(a, b)\n",
    "\n",
    "    \n",
    "#df_total['regionidzip'] = df_total.apply(lambda x: zipcalc(x['latitude'], x['longitude']), axis=1)\n",
    "\n",
    "\n",
    "\n",
    "n = 0\n",
    "for i, row in df_total.iterrows():\n",
    "    n+=1\n",
    "    if n == 100:\n",
    "        time.sleep(1)\n",
    "        n = 0\n",
    "    row['regionidzip'] = zipcalc(row['latitude'], row['longitude'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyzipcode import ZipCodeDatabase\n",
    "zcdb = ZipCodeDatabase()\n",
    "zcdb.find_zip(latitude=a['latitude']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "search = ZipcodeSearchEngine()\n",
    "b = search.by_coordinate(a['latitude'],a['longitude'])\n",
    "b[0].Zipcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_merged17 = df_merged17.dropna(subset=['latitude'])\n",
    "df_merged17 = df_merged17.dropna(subset=['longitude'])\n",
    "df_merged17['latitude'] = df_merged17['latitude'] / 1000000\n",
    "df_merged17['longitude'] = df_merged17['longitude'] / 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uszipcode import ZipcodeSearchEngine\n",
    "\n",
    "search = ZipcodeSearchEngine()\n",
    "\n",
    "zips = pd.DataFrame(columns=['parcelid','calczip'])\n",
    "temp = df_merged17.head()\n",
    "temp['latitude']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i, row in df_merged17.iterrows():\n",
    "    b = search.by_coordinate(row['latitude'],row['longitude'])\n",
    "    zips.loc[len(zips)] = [row['parcelid'],b[0].Zipcode] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zips['calczip'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_merged17['poolcnt'].fillna(0, inplace=True)\n",
    "df_merged17['pooltypeid10'].fillna(0, inplace=True)\n",
    "df_merged17['pooltypeid2'].fillna(0, inplace=True)\n",
    "df_merged17['pooltypeid7'].fillna(0, inplace=True)\n",
    "df_merged17['hashottuborspa'].fillna(False, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df_merged17['pooltypeid10'],df_merged17['pooltypeid2'],df_merged17['pooltypeid7'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pools=['poolcnt','pooltypeid2','pooltypeid7','pooltypeid10','hashottuborspa']\n",
    "df_temp = df_merged17[pools]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_temp2 = df_merged17[pools].dropna(subset=['poolcnt'])\n",
    "df_temp2['pooltypeid10'].fillna(0, inplace=True)\n",
    "df_temp2['pooltypeid2'].fillna(0, inplace=True)\n",
    "df_temp2['pooltypeid7'].fillna(0, inplace=True)\n",
    "df_temp2['hashottuborspa'].fillna(False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp2.groupby('pooltypeid7')['pooltypeid2'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp2.groupby('pooltypeid7')['pooltypeid10'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df_temp2['pooltypeid10'],df_temp2['pooltypeid2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp2['pooltypeid10'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged17['pooltypeid10'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged17.groupby('poolcnt')['pooltypeid10'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_merged17['pooltypeid2'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged17.groupby('poolcnt')['pooltypeid2'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged17.groupby('poolcnt')['pooltypeid7'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged17.groupby('pooltypeid7')['pooltypeid2'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged17.groupby('pooltypeid2')['pooltypeid10'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged17.groupby('hashottuborspa')['pooltypeid2'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_merged17['hashottuborspa'].fillna(False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fill poolcnt na, fill hashottuborspa na\n",
    "\n",
    "pools = pd.DataFrame(columns=['parcelid','pooltype'])\n",
    "        \n",
    "for i, row in df_merged17.iterrows():\n",
    "    if row['hashottuborspa'] and row['poolcnt'] > 0:\n",
    "        pools.loc[len(pools)] = [row['parcelid'],1] \n",
    "    elif not(row['hashottuborspa']) and row['poolcnt'] > 0:\n",
    "        pools.loc[len(pools)] = [row['parcelid'],2] \n",
    "    elif row['hashottuborspa'] and row['poolcnt'] == 0:\n",
    "        pools.loc[len(pools)] = [row['parcelid'],3] \n",
    "    else:\n",
    "        pools.loc[len(pools)] = [row['parcelid'],0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i, row in df_merged17.iterrows():\n",
    "#    if row['pooltypeid2'] = 1:\n",
    "#        row['hashottuborspa'] == True\n",
    "df_merged17['pooltypeid2'].fillna(0, inplace=True)\n",
    "df_merged17.groupby('pooltypeid2')['hashottuborspa'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pools['pooltype'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged17.groupby('propertylandusetypeid')['propertycountylandusecode'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged17['propertyzoningdesc'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
